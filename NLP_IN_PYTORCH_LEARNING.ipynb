{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP IN PYTORCH LEARNING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiAAWTcYOoT1VP9GGeY96M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiSuvamPatnaik/NLP-in-Pytorch/blob/main/NLP_IN_PYTORCH_LEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Custom Embedding layer"
      ],
      "metadata": {
        "id": "D286sK1Mzxhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "190reE4wt3Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW62BhFHzBz5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = \"I am Sai Suvam\"\n",
        "idx = {\"I\":0,\"am\":1,\"Sai\":2,\"Suvam\":3}\n",
        "words = str1.split()\n",
        "res = [idx[i] for i in words]\n",
        "print(res)"
      ],
      "metadata": {
        "id": "dBiWjtUU08co",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591d7f55-230d-418d-8ba1-74ea040cef69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = nn.Embedding(len(res),5)\n",
        "res1 = torch.tensor(res,dtype=torch.long)\n",
        "emb(res1)"
      ],
      "metadata": {
        "id": "-fH9ExQF08_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea27552-17e5-4b45-bfee-6748fb13c37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6644, -0.6022, -0.3188,  0.0688,  1.3071],\n",
              "        [-1.5990, -0.9050, -0.3704, -1.6161,  0.2591],\n",
              "        [-1.2532, -2.1773, -1.1917,  0.4732, -0.4044],\n",
              "        [-0.4601,  1.0004,  1.0516,  1.6927, -1.1280]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(emb(res1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-DkRp78aPSX",
        "outputId": "ba989216-3826-4636-9a13-2723d6db6292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.9767, -2.6840, -0.8293,  0.6185,  0.0338], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wMmhPKfkls_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_H_zUMs0ltCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using pre trained word2vec from gensim library"
      ],
      "metadata": {
        "id": "zoFU5hwJz2Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "Nj8k8xIzcCwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"Other useful internals in Gensim 4.0+ include model.wv.index_to_key, a plain list of the key (word) in each index position, and model.wv.key_to_index, a plain dict mapping keys (words) to their index positions. In pre-4.0 versions, the vocabulary was in the vocab field of the Word2Vec model's wv property, as a dictionary, with the keys being each token (word). So there it was just the usual Python for getting a dictionary's length:\"\n",
        "prc = gensim.utils.simple_preprocess(review_text)\n"
      ],
      "metadata": {
        "id": "Ubk_Tv2wcCz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "    window=3,\n",
        "    min_count=2,\n",
        "    workers=4,\n",
        ")"
      ],
      "metadata": {
        "id": "O3n2Ia-bfm-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab([prc])"
      ],
      "metadata": {
        "id": "5OAWYM9Ml-Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxeFQPOJyYXU",
        "outputId": "0645f501-019b-48a9-f7d2-1e0a9121e2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dictionary': <gensim.models.keyedvectors.Vocab at 0x7feb68dab610>,\n",
              " 'each': <gensim.models.keyedvectors.Vocab at 0x7feb68dab950>,\n",
              " 'in': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f9d0>,\n",
              " 'index': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f0d0>,\n",
              " 'keys': <gensim.models.keyedvectors.Vocab at 0x7feb68dab550>,\n",
              " 'model': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f7d0>,\n",
              " 'of': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f490>,\n",
              " 'plain': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f450>,\n",
              " 'the': <gensim.models.keyedvectors.Vocab at 0x7feb68dabbd0>,\n",
              " 'was': <gensim.models.keyedvectors.Vocab at 0x7feb68dab490>,\n",
              " 'word': <gensim.models.keyedvectors.Vocab at 0x7feb68dabd10>,\n",
              " 'wv': <gensim.models.keyedvectors.Vocab at 0x7feb68d4f990>}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train([prc], total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQpct1-6l-YX",
        "outputId": "3a961c8f-4048-4142-e996-e34b937651fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 350)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.FloatTensor(model.wv.vectors.shape)"
      ],
      "metadata": {
        "id": "OvqR_IyU1H28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"./trial.model\")"
      ],
      "metadata": {
        "id": "VZDoGy9dl-bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(w1=\"index\", w2=\"word\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygrEdgu-l-fO",
        "outputId": "09294a7f-59a1-4b06-d351-617b1002befc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.08971252"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ejzyPGXpvHZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.model import KeyedVectors\n"
      ],
      "metadata": {
        "id": "IoFBs0JtqXWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoW2f3w8qXaY",
        "outputId": "1c4d0e3c-f340-4364-9396-e9c46fb007c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.most_similar(positive=[\"king\",\"women\"],negative=[\"men\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYkcviFTrZg4",
        "outputId": "f61c0dbf-4aad-472e-8b8b-63d4e28b5a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.74156653881073),\n",
              " ('monarch', 0.7021745443344116),\n",
              " ('prince', 0.6327081918716431),\n",
              " ('kingdom', 0.6294623613357544),\n",
              " ('elizabeth', 0.6115030646324158),\n",
              " ('throne', 0.6069279909133911),\n",
              " ('emperor', 0.5794594287872314),\n",
              " ('father', 0.567244291305542),\n",
              " ('son', 0.5642266273498535),\n",
              " ('margaret', 0.5641614198684692)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.vectors[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOHMT7g7rtiS",
        "outputId": "a7a81c2c-b305-46db-8e54-f721aee6672d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Sd5GNrTrA2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7H5pxVT9W-Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PreProcessing in NLP"
      ],
      "metadata": {
        "id": "Jz6UmHN5Y51q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = [\"I want to go out.\",\n",
        "             \" I like to play.\",\n",
        "             \" No eating - \",\n",
        "             \"No play!\",\n",
        "            ]\n",
        "tokenizer = Tokenizer(num_words=100, lower= 1, oov_token=\"<OOV>\")\n",
        "\n",
        "# tokenizer = Tokenizer(num_words=100, lower= 1)\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "id": "hL4T_pNpXbjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abeab29-9504-4e3c-8e69-106e13d40c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'to': 2, 'play': 3, 'no': 4, 'want': 5, 'go': 6, 'out': 7, 'like': 8, 'eating': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sentences)\n",
        "print(word_index)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GLqJW6pZakJ",
        "outputId": "467aa3b4-1b6d-4407-de38-901b849a9861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I want to go out.', ' I like to play.', ' No eating - ', 'No play!']\n",
            "{'i': 1, 'to': 2, 'play': 3, 'no': 4, 'want': 5, 'go': 6, 'out': 7, 'like': 8, 'eating': 9}\n",
            "[[1, 5, 2, 6, 7], [1, 8, 2, 3], [4, 9], [4, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_pad = pad_sequences(sequences, padding='pre')\n",
        "print(\"\\nword_index = \", word_index)\n",
        "print(\"\\nsequences = \", sequences)\n",
        "print(\"\\npadded_seq = \" )\n",
        "print(pre_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRbU00mqbnGc",
        "outputId": "fc6c8cc1-9ee2-475b-bbdb-19977cbce884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "word_index =  {'i': 1, 'to': 2, 'play': 3, 'no': 4, 'want': 5, 'go': 6, 'out': 7, 'like': 8, 'eating': 9}\n",
            "\n",
            "sequences =  [[1, 5, 2, 6, 7], [1, 8, 2, 3], [4, 9], [4, 3]]\n",
            "\n",
            "padded_seq = \n",
            "[[1 5 2 6 7]\n",
            " [1 8 2 3 0]\n",
            " [4 9 0 0 0]\n",
            " [4 3 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepad_maxlen_pretrunc = pad_sequences(sequences, padding =\"pre\", maxlen =4, truncating =\"pre\")\n",
        "print(prepad_maxlen_pretrunc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ-eJnykbnx_",
        "outputId": "6817a812-64fc-446a-f261-39c09c83c9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5 2 6 7]\n",
            " [1 8 2 3]\n",
            " [0 0 4 9]\n",
            " [0 0 4 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_dnmU8nQb_3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HL_q81Phc5BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Vocabulary"
      ],
      "metadata": {
        "id": "LNFCHrSEjjOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.PAD_token = 0   # Used for padding short sentences\n",
        "        self.SOS_token = 1   # Start-of-sentence token\n",
        "        self.EOS_token = 2   # End-of-sentence token\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {self.PAD_token: \"PAD\", self.SOS_token: \"SOS\", self.EOS_token: \"EOS\"}\n",
        "        self.num_words = 3\n",
        "        self.num_sentences = 0\n",
        "        self.longest_sentence = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            # First entry of word into vocabulary\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            # Word exists; increase word count\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "    def add_sentence(self, sentence):\n",
        "        sentence_len = 0\n",
        "        for word in sentence.split(' '):\n",
        "            sentence_len += 1\n",
        "            self.add_word(word)\n",
        "        if sentence_len > self.longest_sentence:\n",
        "            # This is the longest sentence\n",
        "            self.longest_sentence = sentence_len\n",
        "        # Count the number of sentences\n",
        "        self.num_sentences += 1\n",
        "\n",
        "    def to_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def to_index(self, word):\n",
        "        return self.word2index[word]"
      ],
      "metadata": {
        "id": "n0_nWF9xc5Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc = Vocabulary('test')\n",
        "print(voc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnQukEXZf9st",
        "outputId": "beab0e9e-c6c4-45ff-b4cf-2c2f3f17854a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Vocabulary object at 0x7feb6b1044d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"I want to go out.\",\n",
        "             \" I like to play.\",\n",
        "             \" No eating - \",\n",
        "             \"No play!\",\n",
        "            ]\n",
        "\n",
        "\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H2g8cGUgEf5",
        "outputId": "9968ae18-970a-4073-f73e-53b2f9d139f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I want to go out.', ' I like to play.', ' No eating - ', 'No play!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in corpus:\n",
        "  voc.add_sentence(sent)\n",
        "print(voc.word2index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEZUd2vrgmWv",
        "outputId": "7fa20139-f80a-4cdf-8066-41a2a2e6ed39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I': 3, 'want': 4, 'to': 5, 'go': 6, 'out.': 7, '': 8, 'like': 9, 'play.': 10, 'No': 11, 'eating': 12, '-': 13, 'play!': 14}\n",
            "{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 'I', 4: 'want', 5: 'to', 6: 'go', 7: 'out.', 8: '', 9: 'like', 10: 'play.', 11: 'No', 12: 'eating', 13: '-', 14: 'play!'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Token 4 corresponds to token:', voc.to_word(4))\n",
        "print('Token \"this\" corresponds to index:', voc.to_index('this'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw38PySMgma1",
        "outputId": "e1fa61a1-d815-48a6-ba6c-f9973d55f066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 4 corresponds to token: is\n",
            "Token \"this\" corresponds to index: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen = \"\"\n",
        "for word in range(voc.num_words):\n",
        "    print(voc.to_word(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ePo2jcMgmdf",
        "outputId": "fcba54fb-d36d-4597-aba7-411d6f5a6fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PAD\n",
            "SOS\n",
            "EOS\n",
            "I\n",
            "want\n",
            "to\n",
            "go\n",
            "out.\n",
            "\n",
            "like\n",
            "play.\n",
            "No\n",
            "eating\n",
            "-\n",
            "play!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tkns = []\n",
        "sent_idxs = []\n",
        "for word in corpus[3].split(' '):\n",
        "  sent_tkns.append(word)\n",
        "  sent_idxs.append(voc.to_index(word))\n",
        "print(sent_tkns)\n",
        "print(sent_idxs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ41scvBgwYE",
        "outputId": "04f536e0-3dd2-4027-cb3d-9ee46b477d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No', 'play!']\n",
            "[30, 33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NstqhnKJhAUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i01My2nYDGN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']"
      ],
      "metadata": {
        "id": "5tQOFMbGDGXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2. Design the Vocabulary\n",
        "# The default token pattern removes tokens of a single character. That's why we don't have the \"I\" and \"s\" tokens in the output\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Step 3. Create the Bag-of-Words Model\n",
        "bag_of_words = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Show the Bag-of-Words Model as a pandas DataFrame\n",
        "feature_names = count_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "uh7YGBLmDIT8",
        "outputId": "895dc124-db5f-48f3-c529-57c7f564f2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   awesome  funny  hate  like  love  movie  nice\n",
              "0        0      1     0     1     0      1     0\n",
              "1        0      0     1     0     0      1     0\n",
              "2        1      0     0     1     0      0     0\n",
              "3        0      0     0     0     1      0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b93a149d-a1af-4579-a4cf-d5de822e738f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awesome</th>\n",
              "      <th>funny</th>\n",
              "      <th>hate</th>\n",
              "      <th>like</th>\n",
              "      <th>love</th>\n",
              "      <th>movie</th>\n",
              "      <th>nice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b93a149d-a1af-4579-a4cf-d5de822e738f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b93a149d-a1af-4579-a4cf-d5de822e738f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b93a149d-a1af-4579-a4cf-d5de822e738f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s2CT97IsEPiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "values = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Show the Model as a pandas DataFrame\n",
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pd.DataFrame(values.toarray(), columns = feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "yhc0wMiRJsNs",
        "outputId": "6ce4e4ae-aae5-45c4-8719-027edb06ebde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    awesome     funny      hate        it      like      love     movie  \\\n",
              "0  0.000000  0.571848  0.000000  0.365003  0.450852  0.000000  0.450852   \n",
              "1  0.000000  0.000000  0.702035  0.000000  0.000000  0.000000  0.553492   \n",
              "2  0.539445  0.000000  0.000000  0.344321  0.425305  0.000000  0.000000   \n",
              "3  0.000000  0.000000  0.000000  0.345783  0.000000  0.541736  0.000000   \n",
              "\n",
              "       nice       one      this       was  \n",
              "0  0.000000  0.000000  0.365003  0.000000  \n",
              "1  0.000000  0.000000  0.448100  0.000000  \n",
              "2  0.000000  0.000000  0.344321  0.539445  \n",
              "3  0.541736  0.541736  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72531e17-6a1b-4b87-b35c-3c10a0bd67ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awesome</th>\n",
              "      <th>funny</th>\n",
              "      <th>hate</th>\n",
              "      <th>it</th>\n",
              "      <th>like</th>\n",
              "      <th>love</th>\n",
              "      <th>movie</th>\n",
              "      <th>nice</th>\n",
              "      <th>one</th>\n",
              "      <th>this</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.571848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365003</td>\n",
              "      <td>0.450852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.450852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365003</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.702035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.448100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.539445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.344321</td>\n",
              "      <td>0.425305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.344321</td>\n",
              "      <td>0.539445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72531e17-6a1b-4b87-b35c-3c10a0bd67ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72531e17-6a1b-4b87-b35c-3c10a0bd67ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72531e17-6a1b-4b87-b35c-3c10a0bd67ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SkipGram in Pytorch"
      ],
      "metadata": {
        "id": "-eScJfk-VYpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'he is a king',\n",
        "    'she is a queen',\n",
        "    'he is a man',\n",
        "    'she is a woman',\n",
        "    'warsaw is poland capital',\n",
        "    'berlin is germany capital',\n",
        "    'paris is france capital',\n",
        "]"
      ],
      "metadata": {
        "id": "txzu0L1-Vbg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_corpus(corpus):\n",
        "    tokens = [x.split() for x in corpus]\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = tokenize_corpus(corpus)\n",
        "vocabulary = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "\n",
        "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "\n",
        "vocabulary_size = len(vocabulary)\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD4aCk9lVfpm",
        "outputId": "71ed96d5-8ac7-49f7-9da6-8dd8686b6598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'he': 0, 'is': 1, 'a': 2, 'king': 3, 'she': 4, 'queen': 5, 'man': 6, 'woman': 7, 'warsaw': 8, 'poland': 9, 'capital': 10, 'berlin': 11, 'germany': 12, 'paris': 13, 'france': 14}\n",
            "{0: 'he', 1: 'is', 2: 'a', 3: 'king', 4: 'she', 5: 'queen', 6: 'man', 7: 'woman', 8: 'warsaw', 9: 'poland', 10: 'capital', 11: 'berlin', 12: 'germany', 13: 'paris', 14: 'france'}\n",
            "['he', 'is', 'a', 'king', 'she', 'queen', 'man', 'woman', 'warsaw', 'poland', 'capital', 'berlin', 'germany', 'paris', 'france']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "window_size = 2\n",
        "idx_pairs = []\n",
        "for sentence in tokenized_corpus:                                                         # for each sentence\n",
        "    indices = [word2idx[word] for word in sentence]\n",
        "    for center_word_pos in range(len(indices)):                                           # for each word, threated as center word\n",
        "        for w in range(-window_size, window_size + 1):                                    # for each window position\n",
        "            context_word_pos = center_word_pos + w                                        # make sure not jump out sentence\n",
        "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
        "                continue\n",
        "            context_word_idx = indices[context_word_pos]\n",
        "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
        "    # print(indices)\n",
        "    break\n",
        "\n",
        "idx_pairs = np.array(idx_pairs)                                                           # it will be useful to have this as numpy array\n",
        "print(tokenized_corpus[0])\n",
        "for i in idx_pairs:\n",
        "  print(idx2word[i[0]],idx2word[i[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erOA_R59VgkB",
        "outputId": "207cb165-a1d6-4e3a-93d2-d09698b72433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'is', 'a', 'king']\n",
            "he is\n",
            "he a\n",
            "is he\n",
            "is a\n",
            "is king\n",
            "a he\n",
            "a is\n",
            "a king\n",
            "king is\n",
            "king a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "N60zfm1vydjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_layer(word_idx):\n",
        "    x = torch.zeros(vocabulary_size).float()\n",
        "    x[word_idx] = 1.0\n",
        "    return x"
      ],
      "metadata": {
        "id": "5cikmr7uzEZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(idx_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTBnzEn7KulH",
        "outputId": "0553f566-ac34-4be3-9531-d33a93027699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1]\n",
            " [0 2]\n",
            " [1 0]\n",
            " [1 2]\n",
            " [1 3]\n",
            " [2 0]\n",
            " [2 1]\n",
            " [2 3]\n",
            " [3 1]\n",
            " [3 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dims = 5\n",
        "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
        "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
        "num_epochs = 101\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "for epo in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    for data, target in idx_pairs:\n",
        "        x = Variable(get_input_layer(data)).float()\n",
        "        # print(x)\n",
        "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
        "\n",
        "        z1 = torch.matmul(W1, x)\n",
        "        z2 = torch.matmul(W2, z1)\n",
        "    \n",
        "        log_softmax = F.log_softmax(z2, dim=0)\n",
        "\n",
        "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
        "        loss_val += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        W1.data -= learning_rate * W1.grad.data\n",
        "        W2.data -= learning_rate * W2.grad.data\n",
        "\n",
        "        W1.grad.data.zero_()\n",
        "        W2.grad.data.zero_()\n",
        "    \n",
        "    if epo % 10 == 0:    \n",
        "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMPxcVqSV9nz",
        "outputId": "3d7213fb-53d2-4442-e256-206e30ac6806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epo 0: 4.091924154758454\n",
            "Loss at epo 10: 3.9284665405750276\n",
            "Loss at epo 20: 3.7859984934329987\n",
            "Loss at epo 30: 3.6624924719333647\n",
            "Loss at epo 40: 3.555117219686508\n",
            "Loss at epo 50: 3.460879999399185\n",
            "Loss at epo 60: 3.37708575129509\n",
            "Loss at epo 70: 3.301531380414963\n",
            "Loss at epo 80: 3.232516181468964\n",
            "Loss at epo 90: 3.1687616646289825\n",
            "Loss at epo 100: 3.1093174695968626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4c2Kr_P4u450"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQyABfVXMyhA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-UORytM39x"
      },
      "source": [
        "raw_text = \"\"\"During my second month of nursing school, our professor gave us a pop quiz.  \n",
        "I was a conscientious student and had breezed through the questions, until I read the last one: \n",
        "“What is the first name of the woman who cleans the school?”  Surely this was some kind of joke. \n",
        "I had seen the cleaning woman several times. She was tall, dark-haired and in her 50s, but how would I know her name?  \n",
        "I handed in my paper, leaving the last question blank.  Before class ended, one student asked if the last question would count toward our quiz grade.  \n",
        "“Absolutely,” said the professor.  “In your careers you will meet many people. All are significant. They deserve your attention and care, \n",
        "even if all you do is smile and say ‘hello’. I’ve never forgotten that lesson. I also learned her name was Dorothy.\"\"\".split()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "EMDEDDING_DIM = 100\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_list = list(vocab)\n",
        "\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pdVHfr9jp0IL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)\n",
        "print(vocab_size)\n",
        "print(word_to_ix)\n",
        "print(ix_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brj4SR4xp68F",
        "outputId": "ffc0aab1-759e-43c2-a5ee-d7bfebdc3832"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'significant.', '“Absolutely,”', 'read', 'that', 'a', 'lesson.', 'pop', 'name?', 'school?”', 'student', 'During', 'say', 'conscientious', '“In', 'breezed', 'asked', 'I', 'joke.', 'grade.', 'of', 'dark-haired', 'some', 'deserve', 'professor.', 'They', 'if', 'people.', 'one', 'her', 'count', 'professor', 'paper,', 'Before', 'how', 'seen', 'many', 'second', 'is', 'had', 'woman', 'meet', 'She', 'careers', 'in', 'toward', 'my', 'questions,', 'but', 'cleans', 'blank.', 'ended,', 'gave', 'and', 'several', 'school,', 'last', 'Dorothy.', 'also', 'kind', 'quiz', 'your', 'all', '‘hello’.', '50s,', 'Surely', 'us', 'through', 'even', 'learned', 'one:', 'know', 'care,', 'who', 'until', 'All', 'times.', 'quiz.', 'would', 'you', 'I’ve', 'smile', 'our', 'never', 'month', 'do', 'said', 'tall,', 'class', 'cleaning', 'are', 'forgotten', 'leaving', 'the', 'question', 'this', 'attention', 'handed', 'will', 'nursing', 'first', 'was', 'name', '“What'}\n",
            "103\n",
            "{'significant.': 0, '“Absolutely,”': 1, 'read': 2, 'that': 3, 'a': 4, 'lesson.': 5, 'pop': 6, 'name?': 7, 'school?”': 8, 'student': 9, 'During': 10, 'say': 11, 'conscientious': 12, '“In': 13, 'breezed': 14, 'asked': 15, 'I': 16, 'joke.': 17, 'grade.': 18, 'of': 19, 'dark-haired': 20, 'some': 21, 'deserve': 22, 'professor.': 23, 'They': 24, 'if': 25, 'people.': 26, 'one': 27, 'her': 28, 'count': 29, 'professor': 30, 'paper,': 31, 'Before': 32, 'how': 33, 'seen': 34, 'many': 35, 'second': 36, 'is': 37, 'had': 38, 'woman': 39, 'meet': 40, 'She': 41, 'careers': 42, 'in': 43, 'toward': 44, 'my': 45, 'questions,': 46, 'but': 47, 'cleans': 48, 'blank.': 49, 'ended,': 50, 'gave': 51, 'and': 52, 'several': 53, 'school,': 54, 'last': 55, 'Dorothy.': 56, 'also': 57, 'kind': 58, 'quiz': 59, 'your': 60, 'all': 61, '‘hello’.': 62, '50s,': 63, 'Surely': 64, 'us': 65, 'through': 66, 'even': 67, 'learned': 68, 'one:': 69, 'know': 70, 'care,': 71, 'who': 72, 'until': 73, 'All': 74, 'times.': 75, 'quiz.': 76, 'would': 77, 'you': 78, 'I’ve': 79, 'smile': 80, 'our': 81, 'never': 82, 'month': 83, 'do': 84, 'said': 85, 'tall,': 86, 'class': 87, 'cleaning': 88, 'are': 89, 'forgotten': 90, 'leaving': 91, 'the': 92, 'question': 93, 'this': 94, 'attention': 95, 'handed': 96, 'will': 97, 'nursing': 98, 'first': 99, 'was': 100, 'name': 101, '“What': 102}\n",
            "{0: 'significant.', 1: '“Absolutely,”', 2: 'read', 3: 'that', 4: 'a', 5: 'lesson.', 6: 'pop', 7: 'name?', 8: 'school?”', 9: 'student', 10: 'During', 11: 'say', 12: 'conscientious', 13: '“In', 14: 'breezed', 15: 'asked', 16: 'I', 17: 'joke.', 18: 'grade.', 19: 'of', 20: 'dark-haired', 21: 'some', 22: 'deserve', 23: 'professor.', 24: 'They', 25: 'if', 26: 'people.', 27: 'one', 28: 'her', 29: 'count', 30: 'professor', 31: 'paper,', 32: 'Before', 33: 'how', 34: 'seen', 35: 'many', 36: 'second', 37: 'is', 38: 'had', 39: 'woman', 40: 'meet', 41: 'She', 42: 'careers', 43: 'in', 44: 'toward', 45: 'my', 46: 'questions,', 47: 'but', 48: 'cleans', 49: 'blank.', 50: 'ended,', 51: 'gave', 52: 'and', 53: 'several', 54: 'school,', 55: 'last', 56: 'Dorothy.', 57: 'also', 58: 'kind', 59: 'quiz', 60: 'your', 61: 'all', 62: '‘hello’.', 63: '50s,', 64: 'Surely', 65: 'us', 66: 'through', 67: 'even', 68: 'learned', 69: 'one:', 70: 'know', 71: 'care,', 72: 'who', 73: 'until', 74: 'All', 75: 'times.', 76: 'quiz.', 77: 'would', 78: 'you', 79: 'I’ve', 80: 'smile', 81: 'our', 82: 'never', 83: 'month', 84: 'do', 85: 'said', 86: 'tall,', 87: 'class', 88: 'cleaning', 89: 'are', 90: 'forgotten', 91: 'leaving', 92: 'the', 93: 'question', 94: 'this', 95: 'attention', 96: 'handed', 97: 'will', 98: 'nursing', 99: 'first', 100: 'was', 101: 'name', 102: '“What'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"During my second month of nursing school\"\"\"\n",
        "def CBOW(raw_text, window_size=2):\n",
        "    data = []\n",
        "    for i in range(window_size, len(raw_text) - window_size):\n",
        "        context = [raw_text[i - window_size], raw_text[i - (window_size - 1)], raw_text[i + (window_size - 1)], raw_text[i + window_size]]\n",
        "        \n",
        "        # context = raw_text[i - window_size:i + window_size+1]\n",
        "        # context.remove(raw_text[i])                                        //Alternate Way of finding Context Words\n",
        "        \n",
        "        target = raw_text[i]\n",
        "        data.append((context, target))\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "data = CBOW(raw_text)\n",
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmQwIB9qjWN",
        "outputId": "4ebb3daa-09e1-4346-c543-067d7c7588a3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['During', 'my', 'month', 'of'], 'second'),\n",
              " (['my', 'second', 'of', 'nursing'], 'month'),\n",
              " (['second', 'month', 'nursing', 'school,'], 'of'),\n",
              " (['month', 'of', 'school,', 'our'], 'nursing'),\n",
              " (['of', 'nursing', 'our', 'professor'], 'school,'),\n",
              " (['nursing', 'school,', 'professor', 'gave'], 'our'),\n",
              " (['school,', 'our', 'gave', 'us'], 'professor'),\n",
              " (['our', 'professor', 'us', 'a'], 'gave'),\n",
              " (['professor', 'gave', 'a', 'pop'], 'us'),\n",
              " (['gave', 'us', 'pop', 'quiz.'], 'a')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW_Model(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW_Model, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        \n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # print(sum(self.embeddings(inputs)).view(1,-1))\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        # print(\"Output:\",out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "zjEvZC1etOny"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW_Model(vocab_size, EMDEDDING_DIM)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "PRaigtZG0SDT"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPdMf3mu3DNh",
        "outputId": "026c843b-80fa-48e0-d677-37b162c2511d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['During', 'my', 'month', 'of'], 'second')"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "metadata": {
        "id": "FGJy8nA23Olx"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([word_to_ix[target]])\n",
        "target,log_probs"
      ],
      "metadata": {
        "id": "BTComWG95_Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING\n",
        "for epoch in range(1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)  \n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "        break\n",
        "\n",
        "        \n",
        "    # if epoch%10==0:\n",
        "    #       print(\"Epoch {}: {}\".format(epoch,total_loss.data))\n",
        "        \n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTHIvlVN0SG_",
        "outputId": "30fb300b-09d8-4827-d8ec-4202e3f605d6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[-7.8853e-02, -1.4675e-01,  4.6027e-01,  1.3036e+00, -1.7556e-01,\n",
            "         -1.4308e-01, -2.7179e-01, -1.1886e-02,  2.9907e-01, -4.1299e-01,\n",
            "          6.7182e-02,  9.4632e-01, -5.4379e-01, -9.7060e-01, -2.2507e-01,\n",
            "          4.7415e-01,  2.8251e-01, -9.9908e-01, -5.3166e-02,  5.5032e-01,\n",
            "         -2.1709e-01, -5.6844e-01,  7.4841e-01,  7.8129e-01, -2.0405e-01,\n",
            "         -4.7772e-02,  1.6196e-01, -4.3125e-01,  1.0856e-01, -3.3955e-02,\n",
            "          6.5667e-01,  1.3472e+00,  1.1816e+00,  1.3983e-01, -7.6802e-01,\n",
            "          1.4598e-01, -4.9751e-01, -7.4870e-01, -7.0096e-01, -1.2812e+00,\n",
            "          5.2469e-01,  2.6806e-02,  3.2783e-01, -5.2668e-01, -9.4038e-01,\n",
            "         -4.1887e-01,  6.6365e-01,  5.9331e-01,  8.7224e-01, -2.3898e-01,\n",
            "         -1.3840e-01,  1.6173e-01, -8.8392e-01,  9.0439e-01, -8.3500e-02,\n",
            "         -1.3209e-02, -2.5065e-02, -8.0487e-01,  1.4557e-02, -9.1774e-01,\n",
            "          5.0811e-01,  1.0900e-01,  3.3819e-01, -3.8244e-02, -5.4471e-01,\n",
            "         -2.4600e-01, -9.2689e-01, -1.3633e-01,  8.7302e-02,  3.1164e-01,\n",
            "          2.2986e-01,  1.9828e-01, -1.6756e-01, -4.6328e-01,  1.1095e-02,\n",
            "         -4.3314e-01,  3.5543e-01, -5.8178e-01, -8.7976e-01,  9.5128e-02,\n",
            "         -3.5757e-01,  8.7398e-01,  3.7126e-01,  1.0942e-01, -1.0307e+00,\n",
            "         -3.8905e-01,  3.7682e-03, -7.6528e-02, -9.5955e-01, -5.1108e-01,\n",
            "          9.2820e-02,  1.6099e-02,  4.1030e-02,  4.9096e-01,  3.8701e-04,\n",
            "         -2.6339e-01, -1.8475e-01,  2.0995e-01,  6.9858e-01,  1.1280e+00,\n",
            "         -1.9200e-01,  2.8121e-01, -1.6594e-01]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I7LQByAJ0SKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}